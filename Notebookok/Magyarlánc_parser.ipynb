{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Magyarlánc parser",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlI71NRUF7ur"
      },
      "source": [
        "pip install conllu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6RsqvLEF_2g"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEwOdUjsF_z1"
      },
      "source": [
        "from conllu import parse\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpinHuBank_Test.txt és az OpinHuBank_Train.txt fájlokat előbb magyarlánccal le kell futtatni, majd az eredményt itt beolvasni. "
      ],
      "metadata": {
        "id": "ISVmEbj6Kg6R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suquXMl0F_wz"
      },
      "source": [
        "from io import open\n",
        "from conllu import parse_incr\n",
        "\n",
        "files = []\n",
        "\n",
        "data_file = open(\"tesztout_depparse\", \"r\")\n",
        "for tokenlist in parse_incr(data_file,fields=[\"id\", \"form\", \"lemma\", \"UPOSTAG\", \"feats\", \"HEAD\", \"DEPREL\"]):\n",
        "    files.append(tokenlist)\n",
        "    #print(tokenlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRWV6SDEEvUM"
      },
      "source": [
        "def dependency_adj_matrix(sentence):\n",
        "  matrix = np.zeros((len(sentence), len(sentence))).astype('float32') \n",
        "  for word in sentence:\n",
        "    matrix[int(word['id'])-1][int(word['id'])-1] = 1\n",
        "    matrix[int(word['id'])-1][int(word['HEAD'])-1] = 1\n",
        "    matrix[int(word['HEAD'])-1][int(word['id'])-1] = 1\n",
        "  #print(matrix)\n",
        "  return (matrix)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ha ezt futtattuk akkor megkapjuk az OpinHuBank_Test.txt.graph filet"
      ],
      "metadata": {
        "id": "BvDnVABKKx2Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDHUGTr64VEZ"
      },
      "source": [
        "fout = open(\"OpinHuBank_Test.txt\"+'.graph', 'wb')\n",
        "idx2graph = {}\n",
        "for i in range(0, len(files), 3):\n",
        "        adj_matrix = dependency_adj_matrix(files[i])\n",
        "        idx2graph[i+3] = adj_matrix\n",
        "               \n",
        "pickle.dump(idx2graph, fout)        \n",
        "fout.close() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H23q0sy4F_XQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QxFaAEaF_Uk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBm9W6ErF_R8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}